---
title: Sprint4. Del modelo a la aplicaci√≥n
description: En esta actividad, el alumnado se enfrentar√° al reto de construir una aplicaci√≥n real de Machine Learning en Python para resolver un problema de clasificaci√≥n de im√°genes "Perro/Gato". Para ello deber√° utilizar la librer√≠a TensorFlow/Keras. El proyecto abarcar√° el ciclo de vida completo del sw. de IA; recolecci√≥n y preparaci√≥n del datasheet, definici√≥n de la arquitectura del modelo, entrenamiento y evaluaci√≥n cr√≠tica de su rendimiento.
---

En el sprint anterior, hemos aprendido a entrena modelos usando *Teachable Machine*. Hemos ajustado sus hiperpar√°metros y evaluado su rendimiento usando las gr√°ficas generadas autom√°ticamente por la herramienta.

En este sprint vamos a dar un paso m√°s all√° y vamos a construir una aplicaci√≥n real de Machine Learning en Python para resolver un problema de clasificaci√≥n de im√°genes "Perro/Gato".

En esta primera aproximaci√≥n **low-code**, usaremos el modelo entrenado en Teachable Machine y construir la aplicaci√≥n sobre *Google Colab*. Nos centraremos en la **inferencia** haciendo uso de TensorFlow/Keras para cargar el modelo y hacer predicciones.

## Sesi√≥n 1,2. Fases de inferencia

En esta secci√≥n aprederemos las fases de inferencia en un modelo de Machine Learning y c√≥mo implementarlas en Python usando TensorFlow/Keras.

!!! note "Fase 1. Cargar el modelo"

    Previamente a exportar el modelo entrenado en *Teachable Machine* a Python, debemos tener claro algunos conceptos clave.

    **TensorFlow:**

    TensorFlow es una biblioteca de c√≥digo abierto desarrollada por Google que se utiliza para crear, entrenar y desplegar modelos de inteligencia artificial y aprendizaje autom√°tico.

    Todos los modelos de *Teachable Machine* est√°n construidos sobre TensorFlow, y por tanto se exportan en formatos compatibles con √©l.

    Formatos de exportaci√≥n:

    - TensorFlow.js ‚Üí para usar el modelo directamente en una p√°gina web.
    - TensorFlow Lite ‚Üí para integrarlo en una aplicaci√≥n m√≥vil o un microcontrolador.
    - TensorFlow (formato est√°ndar *Keras* o *SavedModel*) ‚Üí para usarlo en Python o en proyectos de IA.

    En esta fase, exportaremos el modelo en formato TensorFlow est√°ndar **Keras**. Keras es una biblioteca de alto nivel para el desarrollo de redes neuronales artificiales. En pocas palabras,** Keras es una interfaz amigable para construir y entrenar modelos de IA**.

    ![exportar modelo](./assets/exportarKeras.png){width=40% .center}

    Se descargar√° un archivo comprimido (.zip) que contiene:

    - El modelo en formato Keras (.h5).
    - El archivo labels.txt con las etiquetas de las clases.

    Descomprime el archivo y verifica que tienes ambos archivos. S√∫belo a tu *Google Drive* para que est√© accesible desde *Google Colab*.

    Ahora, en Python, usaremos *TensorFlow/Keras* para cargar el modelo y las etiquetas.

    ```python
    from tensorflow import keras

    #Carga el modelo
    mi_modelo = keras.models.load_model("keras_model.h5", compile=False)

    # Carga las etiquetas de las clases
    nombre_clases = open("labels.txt", "r").readlines()

    print(nombre_clases)
    ```

    El par√°metro `compile=False` se usa para evitar que *Keras* intente compilar el modelo al cargarlo, lo cual no es necesario para la inferencia.

    AVISO üëÄ: Google Colab ha actualizado la librer√≠a Keras a la versi√≥n 3.0, mientras que Teachable Machine exporta los modelos en formato Keras 2.x. Por tanto, debemos indicar el siguiente par√°metro para garantizar la compatibilidad.

    ```python
    import os
    # 1. Activamos el modo legacy (Keras 2)
    os.environ['TF_USE_LEGACY_KERAS'] = '1'
    ``` 

!!! note "Fase 2: Adquirir Datos Nuevos"

    Cargar una imagen (desde un archivo, la webcam, el m√≥vil...).

    En esta primera aproximaci√≥n, usaremos im√°genes almacenadas en archivos. Deber√°s cargar la imagen o imagenes que quieras clasificar a Google Colab.

    Para cargar im√°genes en Python, usaremos la librer√≠a `PIL` (Python Imaging Library), en concreto la clase `Image` e `ImageOps` ('from PIL import Image, ImageOps').

    Ahora estamos en disposici√≥n de cargar una imagen desde un archivo:

    ```python
    imagen= Image.open("<IMAGE_PATH>").convert("RGB")
    ```

    - `<IMAGE_PATH>` debe ser la ruta al archivo de imagen que quieres cargar.
    - `convert("RGB")` se usa para asegurarse de que la imagen est√° en formato RGB (3 canales de color).



!!! note "Fase 3: Pre-procesamiento"
    
    La imagen DEBE transformarse para ser id√©ntica a las de entrenamiento.

    Esto incluye:

    - **Cambiar tama√±o de la imagen para que tenga al menos 224x224 p√≠xeles y luego se recorta desde el centro.**
  
    ```python
    size = (224, 224)
    imagen = ImageOps.fit(imagen, size, Image.Resampling.LANCZOS)
    ```
    
    - **Normalizar los valores de los p√≠xeles (ej. de [0, 255] a [-1, 1]).** Para ello deberemos utilizar la librer√≠a *Numpy* (`√¨mport numpy as np`)

    ```python
    # Convertimos la imagen en un array NumPy.
    imagen_array = np.asarray(imagen)
    ```
    De esta forma, cada p√≠xel de la imagen pasa a representarse como un **n√∫mero entero** (Los valores estar√°n entre 0 y 255) dentro de una matriz tridimensional. Recueda que una imagen *RGB*, cada pixel est√° codificado por tres valores (*Red*, *Green* y *Blue*). Por tanto, si ejecutamos `image_array.shape`, saldr√° (224,224,3)

    Podr√≠amos obtener las dimensiones del array usando: 'print(imagen_array.shape)', el resultado ser√≠a (224, 224, 3). Esto indica que tenemos una matriz tridimensional de 224 filas, 224 columnas y en cada celda hay 3 valores (canales RGB).

    Para convertir los n√∫meros enteros de la matriz a un rango entre -1 y +1 que es lo que espera el modelo preentrenado de *Teachable Machine*, dividiremos el valor de cada celda entre `127.5`. Lo que nos generar√° un valor real entre 0 y 2. 

    Por √∫ltimo. para desplazar el valor entre -1 y +1, le restaremos -1 a cada valor de la celda.

    Debemos tener en cuenta, que `image_array` inicial contiene valores enteros, por lo que debemos como primer paso antes de ejecutar cualquier operaci√≥n aplicarle un *casting* de tipo y convertirlos en numeros reales.

    ```python
    normalizada_imagen_array = (imagen_array.astype(np.float32) / 127.5) - 1
    ```

!!! note "Fase 4: Predicci√≥n"

    Normalmente, las IAs no procesan im√°genes "una a una", sino en lotes. Aunque solo tengamos una foto, debemos meterla en un array de 1 hueco. Ese hueco, a su vez, debe contener la imagen pre-procesada.

    ```python
    # Crear un array para un lote de 1 imagen. ndarray = N-Dimensional Array
    lote_imagenes = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)
    ```
    Ahora, metemos la imagen pre-procesada en el lote:

    ```python
    lote_imagenes[0] = normalizada_imagen_array
    ```

    Para clasificar la imagen preprocesada, usamos el m√©todo `predict()` del modelo cargado en la *Fase 1* ('mi_modelo').

    `predict` est√° dise√±ado para procesar conjuntos de datos a la vez. Por eso, necesita recibir una lista (un lote), aunque esa lista solo tenga un elemento (la foto en la posici√≥n 0).
    
    ```python
    resultados= mi_modelo.predict(lote_imagenes)
    ```

    La funci√≥n `predict` devuelve por cada elemento que contiene 'lote_imagenes' un array de n√∫meros que representan la probabilidad de que la imagen pertenezca a cada clase. En nuestro caso, al tener dos clases y solo una imagen resultados tendr√° la forma [[0.98, 0.02]].


!!! note "Fase 5: Post-procesamiento"

    En esta fase se busca el √≠ndice del n√∫mero m√°s alto en el array devuelto por el modelo (en [0.98, 0.02] ser√≠a el √≠ndice 0). Se usa el √≠ndice para buscar en la lista de etiquetas (labels.txt) y se muestra la etiqueta correspondiente (ej. "Perro").

    Para ello, usaremos la funci√≥n `argmax()` de Numpy. Esta funci√≥n devuelve el √≠ndice que ocupa el valor m√°ximo en un array.

    ```python
    indice = np.argmax(resultados[0])
    ```

    Con este √≠ndice, podemos obtener la etiqueta correspondiente de la lista de etiquetas cargada en la Fase 1.

    ```python
    etiqueta = nombre_clases[indice]
    print("La imagen es de clase: ", etiqueta)
    ```
    y la probabilidad asociada:

    ```python
    probabilidad = resultados[0][indice]
    print("Con una probabilidad de: ", probabilidad)
    ```



!!! question "A106.1 Exportaci√≥n de un modelo desde Teachable Machine"

    Siguiendo los pasos anteriores, crea un cuaderno de *Google Colab* que implemente las fases de inferencia para el modelo entrenado en *Teachable Machine*. **Recuerda seleccionar el entorno de ejecuci√≥n con GPU**.

    Indica en Google Colab todos los pasos realizados y comenta el c√≥digo para explicar cada fase.

    Para cargar el modelo de la fase 1, es recomendable subir el modelo y las im√°genes de testeo al Drive descomprimido, y montar el drive en Google Colab. Seleccionar el archivo y copiar la ruta desde el men√∫ contextual.

## Sesi√≥n 3,4: Evaluaci√≥n en lote

En esta secci√≥n, evaluaremos el rendimiento del modelo en un conjunto de datos de prueba. El objetivo es automatizar la inferencia para todas las imagenes que se encuentren en una carpeta y generar como salida un informe con las predicciones realizadas. 

!!! question "A106.2 Preparaci√≥n del Lote y refactorizar el codigo (1¬™ parte)"

    1. En Google Drive, debemos tener una carpeta `test` que contiene las im√°genes de prueba.
    2. Vamos a crear una variable que contenga un array con el nombre de cada imagen de prueba. Para ello, usaremos la librer√≠a `os` de Python.

    ```python
    lista_archivos = os.listdir("<TEST_CARPETA_PATH>")
    ```

    Si imprimimos `lista_archivos`, veremos que contiene el nombre de cada imagen en la carpeta de prueba `print(lista_archivos)`.

    3. Vamos a inicializar contadores para llevar la cuenta de aciertos y errores.

    ```python
    total_predicciones = 0
    aciertos = 0
    media_probabilidad_aciertos = 0.0
    # predicciones incorrectas contendr√° una lista con los nombres de las im√°genes mal clasificadas
    predicciones_incorrectas = []
    ```
    4. Ahora deber√≠amos recorrer el array `lista_archivos` y para cada imagen, ejecutar las fases de inferencia vistas en la secci√≥n anterior. 

    ```python
    for nombre_archivo in lista_archivos:
        if cat in nombre_archivo:
            etiqueta_esperada = "gato"
        elif dog in nombre_archivo:
            etiqueta_esperada = "perro"
        else:
            continue  # Saltar archivos que no sean de gatos o perros
            
        total_predicciones += 1
        
        ruta_imagen = os.path.join("<TEST_CARPETA_PATH>", nombre_archivo)
        
        # Aqu√≠ obtendriamos la predicci√≥n del modelo llamando a una funci√≥n que 
        # implemente las fases de inferencia
        etiqueta_predicha, probabilidad = predecir_imagen(ruta_imagen)

        if etiqueta_predicha == etiqueta_esperada:
            aciertos += 1
            media_probabilidad_aciertos += probabilidad
        else:
            info_error= {"archivo": nombre_archivo, "prediccion": etiqueta_predicha, 
                 "probabilidad": probabilidad}
            predicciones_incorrectas.append(info_error)
    ```

    5. Deber√°s desarrollar la funci√≥n `predecir_imagen(ruta_imagen)` que implemente las fases de inferencia vistas en la secci√≥n anterior. Esta funci√≥n debe recibir la ruta de una imagen, procesarla y devolver la etiqueta predicha y la probabilidad asociada.


## Sesi√≥n 5,6: Publicaci√≥n de resultados (*Github*)

Finalmente, vamos a calcular las m√©tricas de rendimiento del modelo y generar un informe con los resultados obtenidos. Para ello, usaremos los contadores inicializados en la secci√≥n anterior y generaremos un informe que publicaremos en un repositorio de GitHub, el cual nos servir√° como portafolio de proyectos.

!!! question "A106.3 - C√°lculo de m√©tricas y generaci√≥n del informe"

    1. Calculamos la precisi√≥n del modelo y la probabilidad media de aciertos.

    ```python
    precision = aciertos / total_predicciones if total_predicciones > 0 else 0
    media_probabilidad_aciertos /= aciertos if aciertos > 0 else 1
    ```

    2. Generamos el informe con los resultados obtenidos.

    ```python
    informe = f"""
    Informe de Evaluaci√≥n del Modelo

    Total de predicciones: {total_predicciones}
    Aciertos: {aciertos}
    Precisi√≥n: {precision:.2%}
    Probabilidad media de aciertos: {media_probabilidad_aciertos:.2%}

    Predicciones incorrectas:
    """

    for error in predicciones_incorrectas:
        informe += f"Archivo: {error['archivo']}, Predicci√≥n: 
            {error['prediccion']}, Probabilidad: {error['probabilidad']:.2%}\n"

    print(informe)
    ```

Github surgi√≥ como  una plataforma de desarrollo colaborativo de software para alojar proyectos utilizando el sistema de control de versiones Git. Permite a los desarrolladores trabajar juntos en proyectos, gestionar cambios en el c√≥digo fuente y colaborar de manera eficiente.

En nuestro caso, vamos a usar GitHub para publicar el cuaderno *Jupyter* generado con *Google Colab* y compartir nuestro proyecto con la comunidad. B√°sicamente, utilizaremos GitHub como **portafolio profesional**.

!!! question "A106.4 - Publicaci√≥n en GitHub"

    Para conectar Google Colab con GitHub, necesitas dominar solo tres t√©rminos b√°sicos. No necesitas memorizar comandos complejos todav√≠a, solo entender la l√≥gica:

    #### El Repositorio (Repo)

    Es como una "carpeta de proyecto". Contiene todos los archivos de tu proyecto (c√≥digo, im√°genes, documentaci√≥n) y, lo m√°s importante, el historial de cambios de cada archivo.

    **- Crea un repositorio con un nombre suficientemente significativo, relacionado con el contenido.**

    En la creaci√≥n del repositiorio, indica una descripci√≥n breve del proyecto y selecciona la opci√≥n de inicializar el repositorio con un archivo **README.md**.

    El archivo `README.md` es un archivo de texto en formato Markdown que sirve como la p√°gina principal de tu repositorio. Aqu√≠ puedes describir el prop√≥sito del proyecto, c√≥mo usarlo, c√≥mo contribuir, etc. En nuestro caso, lo usaras para realizar una descripci√≥n general del proyecto que has desarrollado en Google Colab.

    Los repositorios pueden ser **p√∫blicos** (cualquiera puede verlos) o **privados** (solo t√∫ y las personas que invites pueden verlos). Para un portafolio profesional, generalmente querr√°s que sean p√∫blicos. 

    #### Commit (Confirmaci√≥n)

    Un *commit* no es solo "guardar". Es sacar una fotograf√≠a exacta de tu c√≥digo en un momento concreto.

    Cada *commit* tiene un identificador √∫nico y debe llevar un mensaje explicativo (ej: "A√±adida funci√≥n para calcular n√∫meros primos").

    #### Rama (Branch)

    Esto nos permite "viajar en el tiempo": si rompes algo hoy, puedes volver a la foto exacta de ayer. Esto es parte de las herramientas de mantenimiento y optimizaci√≥n de software.

    magina una l√≠nea de tiempo. La l√≠nea principal se llama **main**.

    Todos los cambios que aprobemos ir√°n a esta rama principal. Por ahora, trabajaremos siempre sobre la rama main para mantener nuestro portfolio sencillo y lineal.


    #### De Google Colab a GitHub

    Google Colab tiene una integraci√≥n nativa que facilita enormemente la gesti√≥n documental. 

    El proceso conceptual que realizaremos en cada pr√°ctica es el siguiente:

    - Codificaci√≥n: Creas y pruebas tu c√≥digo Python en los cuadernos de Google Colab .

    Vinculaci√≥n: En el men√∫ de Colab, seleccionas Archivo > Guardar una copia en GitHub.

    - Autorizaci√≥n: La primera vez, tendr√°s que dar permiso a Google para escribir en tu GitHub.

    - Publicaci√≥n (El *Commit*):

        * Seleccionas tu repositorio.

        * Escribes el mensaje del *commit*.

        * Marcas la opci√≥n "Incluir un enlace a Colaboratory". Esto crea un bot√≥n en tu GitHub para que cualquiera (incluido yo para corregir) pueda abrir y ejecutar tu c√≥digo con un clic.

## Sesi√≥n 7,8: Despliegue de la aplicaci√≥n en la nube

Hasta ahora, hemos trabajado en **Google Colab**. Eso es el equivalente a un un entorno controlado para entrenar y experimentar.

Para que nuestra IA "Gatos vs. Perros" pueda ser usada por cualquier persona con un m√≥vil, necesitamos sacarla de Colab y llevarla a **Producci√≥n**. Para ello, utilizaremos tres tecnolog√≠as clave:

* **Streamlit**: Para crear la interfaz visual (Frontend).
* **GitHub Codespaces**: Para programar el c√≥digo de la aplicaci√≥n (Entorno de Desarrollo).
* **Streamlit Cloud**: Para publicar la aplicaci√≥n en Internet (Servidor/Hosting).

**Streamlit** es una librer√≠a de Python de c√≥digo abierto que permite crear aplicaciones web interactivas dise√±adas espec√≠ficamente para ciencia de datos y aprendizaje autom√°tico. A diferencia del desarrollo web tradicional (HTML/CSS/JavaScript), Streamlit permite crear la interfaz completa usando solo Python. Esto nos permite centrarnos en la l√≥gica de la IA sin perder tiempo en el dise√±o visual.

**Github codespaces** es un entorno de desarrollo alojado en la nube. GitHub te ‚Äúpresta‚Äù un contenedor (un entorno Linux aislado) con una versi√≥n web de Visual Studio Code, que funciona directamente en tu navegador.

**Streamlit Cloud: El Servidor de Producci√≥n** es una plataforma "PaaS" (Platform as a Service). Se conecta a tu repositorio de GitHub, lee tu c√≥digo y levanta un servidor web accesible desde cualquier lugar del mundo.

La gran ventaja es que proporcionar acceso web *https* seguro a nuestra aplicaci√≥n, algo imprescindible para que los navegadores permitan el acceso a los dispositivos de captura (c√°mara y micr√≥fono).

**Integraci√≥n Continua (CI/CD B√°sico)** Streamlit Cloud "escucha" a GitHub. Cada vez que guardas un cambio en tu c√≥digo (haces un *commit*), Streamlit Cloud detecta el cambio, baja la nueva versi√≥n y reinicia la aplicaci√≥n autom√°ticamente.

### Resumen del Flujo de Datos (Arquitectura del Proyecto)

Podemos esquematizar nuestro flujo de datos de nuestro proyecto as√≠:

1. **Entrenamiento**: Modelo que hemos entrenado en *Teachable Machine* y exportado en formato Keras (.h5).
2. **Desarrollo**: En nuestro repositorio de GitHub creamos una carpeta donde alojaremos la aplicaci√≥n. Dentro de esta carpeta crearemos un archivo con extensi√≥n *.py*. En la misma carpeta subiremos el modelo exportado (.h5) y el archivo de etiquetas (labels.txt).
3. **Almacenamiento**: GitHub guarda el c√≥digo y el modelo.
4. **Despliegue**: Streamlit Cloud descarga todo desde GitHub y lo ejecuta.
5. **Uso**: Se accede por medio del m√≥vil o escritorio mediante HTTPS a la aplicaci√≥n, se toma la foto y recibe la predicci√≥n (Gato o Perro).
 
!!! note "A107.1 - Preparaci√≥n de archivos"

    1. Crea dentro del repositorio de GitHub una carpeta llamada `app`.
    2. Dentro de la carpeta `app`, crea un archivo llamado `app.py`. Este archivo contendr√° el c√≥digo de la aplicaci√≥n Streamlit.
    3. Sube el modelo exportado desde Teachable Machine (`keras_model.h5`) y el archivo de etiquetas (`labels.txt`) a la carpeta `app`.
    4. Crea un archivo llamado `requirements.txt` en la carpeta `app`. Este archivo debe listar todas las librer√≠as de Python que tu aplicaci√≥n necesita para funcionar. Debe contener las siguientes l√≠neas:

    ```
    tensorflow==2.15
    tf_keras
    streamlit
    pillow
    numpy
    ```

!!! note "A107.2 - Conectar con Streamlit Cloud"

    1. Ve a [Streamlit Cloud](https://streamlit.io/cloud) y reg√≠strate o inicia sesi√≥n con tu cuenta de GitHub.
    2. Haz clic en "New app" (Nueva aplicaci√≥n).
    3. Selecciona el repositorio donde tienes tu proyecto.
    4. Selecciona la rama (normalmente `main`) y la carpeta donde est√° tu aplicaci√≥n (`app`).
    5. Haz clic en "Deploy" (Desplegar).

    Streamlit Cloud comenzar√° a construir y desplegar tu aplicaci√≥n. Esto puede tardar unos minutos. Obviamente, como no tenemos nada en nuestro archivo `app.py`, la aplicaci√≥n no har√° nada todav√≠a.


!!! note "A107.3 - Desarrollo de la aplicaci√≥n Streamlit I"

    Introduce el siguiente c√≥digo en el archivo √†pp.py` para cargar las librer√≠as necesarias y configurar el t√≠tulo de la aplicaci√≥n:

    ```python
    import os
    # Esto obliga a TensorFlow a usar el modo compatibilidad con versiones antiguas
    os.environ['TF_USE_LEGACY_KERAS'] = '1'

    import streamlit as st
    from tensorflow import keras  
    from PIL import Image, ImageOps  
    import numpy as np

    # Configuraci√≥n de la p√°gina
    st.set_page_config(page_title="Reconocimiento Perros vs Gatos", page_icon="üêæ")

    st.title("üê∂ Detector de Mascotas üê±")
    st.write("Usa la c√°mara para saber si es un perro o un gato.")
    ```

    Una vez guardados los cambios (*commit*), Streamlit Cloud detectar√° el cambio, reconstruir√° y reiniciar√° la aplicaci√≥n autom√°ticamente.

    Verifica que la aplicaci√≥n se carga correctamente en el navegador.

!!! note "A107.4 - Desarrollo de la aplicaci√≥n Streamlit II"

    ```python
    # DEFINIMOS UNA FUNCI√ìN PARA CARGAR EL MODELO Y GUARDARLO EN CACHE
    # Usamos cache para que no se cargue cada vez que detecta un movimiento
    @st.cache_resource
    def carga_modelo():
        # Cargamos el modelo
        modelo = keras.models.load_model("st-app/keras_model.h5", compile=False)
        # Carga las etiquetas de las clases
        clases = open("st-app/labels.txt", "r").readlines()
        return modelo, clases


    # 1.CARGAMOS EL MODELO Y ETIQUETAS
    try:
        mi_modelo, nombre_clases = carga_modelo()
    except Exception as e:
        st.error(f"Error al cargar el modelo: {e}")
        st.stop()
    ```

    La directiva `@st.cache_resource` indica a Streamlit que almacene en cach√© el resultado de la funci√≥n. De esta manera, el modelo solo se cargar√° una vez, mejorando el rendimiento de la aplicaci√≥n.

!!! note "A107.5 - Desarrollo de la aplicaci√≥n Streamlit III"

    ```python

    # 2. CAPTURAMOS LA IMAGEN HACIENDO USO DE LA C√ÅMARA
    imagen_camara = st.camera_input("Haz una foto")

    # 3. PREDICCI√ìN
    if imagen_camara is not None:
        imagen = Image.open(imagen_camara).convert("RGB")
        imagen = ImageOps.fit(imagen, (224, 224), Image.Resampling.LANCZOS)
        imagen_array = np.asarray(imagen)
        normalizada_imagen_array = (imagen_array.astype(np.float32) / 127.5) - 1
    # Crear un array para un lote de 1 imagen. ndarray = N-Dimensional Array
    lote_imagenes = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)
    lote_imagenes[0] = normalizada_imagen_array

    # Predicci√≥n
    resultados= mi_modelo.predict(lote_imagenes)
    indice = np.argmax(resultados[0])
    etiqueta = nombre_clases[indice]
    probabilidad = resultados[0][indice]

    st.divider() # L√≠nea separadora visual

    if "Perro" in etiqueta:
            st.success(f"¬°Es un **PERRO**! üê∂")
            st.balloons() # Efecto visual
    else:
            st.success(f"¬°Es un **GATO**! üê±")
            st.snow() # Efecto visual
            
    st.write(f"Estoy un {probabilidad:.2%} seguro.")
    ```

!!! question "A107 - Despliegue de la aplicaci√≥n en Streamlit"

    Completa el desarrollo de la aplicaci√≥n Streamlit siguiendo los pasos anteriores.
  
**Recursos:**

- [Documentaci√≥n oficial de Streamlit](https://docs.streamlit.io/)
