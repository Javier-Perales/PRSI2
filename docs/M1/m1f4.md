---
title: Sprint4. Del modelo a la aplicaci√≥n
description: En esta actividad, el alumnado se enfrentar√° al reto de construir una aplicaci√≥n real de Machine Learning en Python para resolver un problema de clasificaci√≥n de im√°genes "Perro/Gato". Para ello deber√° utilizar la librer√≠a TensorFlow/Keras. El proyecto abarcar√° el ciclo de vida completo del sw. de IA; recolecci√≥n y preparaci√≥n del datasheet, definici√≥n de la arquitectura del modelo, entrenamiento y evaluaci√≥n cr√≠tica de su rendimiento.
---

En el sprint anterior, hemos aprendido a entrena modelos usando *Teachable Machine*. Hemos ajustado sus hiperpar√°metros y evaluado su rendimiento usando las gr√°ficas generadas autom√°ticamente por la herramienta.

En este sprint vamos a dar un paso m√°s all√° y vamos a construir una aplicaci√≥n real de Machine Learning en Python para resolver un problema de clasificaci√≥n de im√°genes "Perro/Gato".

En esta primera aproximaci√≥n **low-code**, usaremos el modelo entrenado en Teachable Machine y construir la aplicaci√≥n sobre *Google Colab*. Nos centraremos en la **inferencia** haciendo uso de TensorFlow/Keras para cargar el modelo y hacer predicciones.

## Sesi√≥n 1,2. Fases de inferencia

En esta secci√≥n aprederemos las fases de inferencia en un modelo de Machine Learning y c√≥mo implementarlas en Python usando TensorFlow/Keras.

!!! note "Fase 1. Cargar el modelo"

    Previamente a exportar el modelo entrenado en *Teachable Machine* a Python, debemos tener claro algunos conceptos clave.

    **TensorFlow:**

    TensorFlow es una biblioteca de c√≥digo abierto desarrollada por Google que se utiliza para crear, entrenar y desplegar modelos de inteligencia artificial y aprendizaje autom√°tico.

    Todos los modelos de *Teachable Machine* est√°n construidos sobre TensorFlow, y por tanto se exportan en formatos compatibles con √©l.

    Formatos de exportaci√≥n:

    - TensorFlow.js ‚Üí para usar el modelo directamente en una p√°gina web.
    - TensorFlow Lite ‚Üí para integrarlo en una aplicaci√≥n m√≥vil o un microcontrolador.
    - TensorFlow (formato est√°ndar *Keras* o *SavedModel*) ‚Üí para usarlo en Python o en proyectos de IA.

    En esta fase, exportaremos el modelo en formato TensorFlow est√°ndar **Keras**. Keras es una biblioteca de alto nivel para el desarrollo de redes neuronales artificiales. En pocas palabras,** Keras es una interfaz amigable para construir y entrenar modelos de IA**.

    ![exportar modelo](./assets/exportarKeras.png){width=40% .center}

    Se descargar√° un archivo comprimido (.zip) que contiene:

    - El modelo en formato Keras (.h5).
    - El archivo labels.txt con las etiquetas de las clases.

    Descomprime el archivo y verifica que tienes ambos archivos. S√∫belo a tu *Google Drive* para que est√© accesible desde *Google Colab*.

    Ahora, en Python, usaremos *TensorFlow/Keras* para cargar el modelo y las etiquetas.

    ```python
    from tensorflow import keras

    #Carga el modelo
    mi_modelo = keras.models.load_model("keras_model.h5", compile=False)

    # Carga las etiquetas de las clases
    nombre_clases = open("labels.txt", "r").readlines()

    print(nombre_clases)
    ```

    El par√°metro `compile=False` se usa para evitar que *Keras* intente compilar el modelo al cargarlo, lo cual no es necesario para la inferencia.

    AVISO üëÄ: Google Colab ha actualizado la librer√≠a Keras a la versi√≥n 3.0, mientras que Teachable Machine exporta los modelos en formato Keras 2.x. Por tanto, debemos indicar el siguiente par√°metro para garantizar la compatibilidad.

    ```python
    import os
    # 1. Activamos el modo legacy (Keras 2)
    os.environ['TF_USE_LEGACY_KERAS'] = '1'
    ``` 

!!! note "Fase 2: Adquirir Datos Nuevos"

    Cargar una imagen (desde un archivo, la webcam, el m√≥vil...).

    En esta primera aproximaci√≥n, usaremos im√°genes almacenadas en archivos. Deber√°s cargar la imagen o imagenes que quieras clasificar a Google Colab.

    Para cargar im√°genes en Python, usaremos la librer√≠a `PIL` (Python Imaging Library), en concreto la clase `Image` e `ImageOps` ('from PIL import Image, ImageOps').

    Ahora estamos en disposici√≥n de cargar una imagen desde un archivo:

    ```python
    imagen= Image.open("<IMAGE_PATH>").convert("RGB")
    ```

    - `<IMAGE_PATH>` debe ser la ruta al archivo de imagen que quieres cargar.
    - `convert("RGB")` se usa para asegurarse de que la imagen est√° en formato RGB (3 canales de color).



!!! note "Fase 3: Pre-procesamiento"
    
    La imagen DEBE transformarse para ser id√©ntica a las de entrenamiento.

    Esto incluye:

    - **Cambiar tama√±o de la imagen para que tenga al menos 224x224 p√≠xeles y luego se recorta desde el centro.**
  
    ```python
    size = (224, 224)
    imagen = ImageOps.fit(imagen, size, Image.Resampling.LANCZOS)
    ```
    
    - **Normalizar los valores de los p√≠xeles (ej. de [0, 255] a [-1, 1]).** Para ello deberemos utilizar la librer√≠a *Numpy* (`√¨mport numpy as np`)

    ```python
    # Convertimos la imagen en un array NumPy.
    imagen_array = np.asarray(imagen)
    ```
    De esta forma, cada p√≠xel de la imagen pasa a representarse como un **n√∫mero entero** (Los valores estar√°n entre 0 y 255) dentro de una matriz tridimensional. Recueda que una imagen *RGB*, cada pixel est√° codificado por tres valores (*Red*, *Green* y *Blue*). Por tanto, si ejecutamos `image_array.shape`, saldr√° (224,224,3)

    Podr√≠amos obtener las dimensiones del array usando: 'print(imagen_array.shape)', el resultado ser√≠a (224, 224, 3). Esto indica que tenemos una matriz tridimensional de 224 filas, 224 columnas y en cada celda hay 3 valores (canales RGB).

    Para convertir los n√∫meros enteros de la matriz a un rango entre -1 y +1 que es lo que espera el modelo preentrenado de *Teachable Machine*, dividiremos el valor de cada celda entre `127.5`. Lo que nos generar√° un valor real entre 0 y 2. 

    Por √∫ltimo. para desplazar el valor entre -1 y +1, le restaremos -1 a cada valor de la celda.

    Debemos tener en cuenta, que `image_array` inicial contiene valores enteros, por lo que debemos como primer paso antes de ejecutar cualquier operaci√≥n aplicarle un *casting* de tipo y convertirlos en numeros reales.

    ```python
    normalizada_imagen_array = (imagen_array.astype(np.float32) / 127.5) - 1
    ```

!!! note "Fase 4: Predicci√≥n"

    Normalmente, las IAs no procesan im√°genes "una a una", sino en lotes. Aunque solo tengamos una foto, debemos meterla en un array de 1 hueco. Ese hueco, a su vez, debe contener la imagen pre-procesada.

    ```python
    # Crear un array para un lote de 1 imagen. ndarray = N-Dimensional Array
    lote_imagenes = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)
    ```
    Ahora, metemos la imagen pre-procesada en el lote:

    ```python
    lote_imagenes[0] = normalizada_imagen_array
    ```

    Para clasificar la imagen preprocesada, usamos el m√©todo `predict()` del modelo cargado en la *Fase 1* ('mi_modelo').

    `predict` est√° dise√±ado para procesar conjuntos de datos a la vez. Por eso, necesita recibir una lista (un lote), aunque esa lista solo tenga un elemento (la foto en la posici√≥n 0).
    
    ```python
    resultados= mi_modelo.predict(lote_imagenes)
    ```

    La funci√≥n `predict` devuelve por cada elemento que contiene 'lote_imagenes' un array de n√∫meros que representan la probabilidad de que la imagen pertenezca a cada clase. En nuestro caso, al tener dos clases y solo una imagen resultados tendr√° la forma [[0.98, 0.02]].


!!! note "Fase 5: Post-procesamiento"

    En esta fase se busca el √≠ndice del n√∫mero m√°s alto en el array devuelto por el modelo (en [0.98, 0.02] ser√≠a el √≠ndice 0). Se usa el √≠ndice para buscar en la lista de etiquetas (labels.txt) y se muestra la etiqueta correspondiente (ej. "Perro").

    Para ello, usaremos la funci√≥n `argmax()` de Numpy. Esta funci√≥n devuelve el √≠ndice que ocupa el valor m√°ximo en un array.

    ```python
    indice = np.argmax(resultados[0])
    ```

    Con este √≠ndice, podemos obtener la etiqueta correspondiente de la lista de etiquetas cargada en la Fase 1.

    ```python
    etiqueta = nombre_clases[indice]
    print("La imagen es de clase: ", etiqueta)
    ```
    y la probabilidad asociada:

    ```python
    probabilidad = resultados[0][indice]
    print("Con una probabilidad de: ", probabilidad)
    ```



!!! question "A106.1 Exportaci√≥n de un modelo desde Teachable Machine"

    Siguiendo los pasos anteriores, crea un cuaderno de *Google Colab* que implemente las fases de inferencia para el modelo entrenado en *Teachable Machine*. **Recuerda seleccionar el entorno de ejecuci√≥n con GPU**.

    Indica en Google Colab todos los pasos realizados y comenta el c√≥digo para explicar cada fase.

    Para cargar el modelo de la fase 1, es recomendable subir el modelo y las im√°genes de testeo al Drive descomprimido, y montar el drive en Google Colab. Seleccionar el archivo y copiar la ruta desde el men√∫ contextual.

## Sesi√≥n 3,4: Evaluaci√≥n en lote

En esta secci√≥n, evaluaremos el rendimiento del modelo en un conjunto de datos de prueba. El objetivo es automatizar la inferencia para todas las imagenes que se encuentren en una carpeta y generar como salida un informe con las predicciones realizadas. 

!!! note "Preparaci√≥n del Lote y refactorizar el codigo (1¬™ parte)"

    1. En Google Drive, debemos tener una carpeta `test` que contiene las im√°genes de prueba.
    2. Vamos a crear una variable que contenga un array con el nombre de cada imagen de prueba. Para ello, usaremos la librer√≠a `os` de Python.

    ```python
    lista_archivos = os.listdir("<TEST_CARPETA_PATH>")
    ```

    Si imprimimos `lista_archivos`, veremos que contiene el nombre de cada imagen en la carpeta de prueba `print(lista_archivos)`.

    3. Vamos a inicializar contadores para llevar la cuenta de aciertos y errores.

    ```python
    total_predicciones = 0
    aciertos = 0
    media_probabilidad_aciertos = 0.0
    # predicciones incorrectas contendr√° una lista con los nombres de las im√°genes mal clasificadas
    predicciones_incorrectas = []
    ```
    4. Ahora deber√≠amos recorrer el array `lista_archivos` y para cada imagen, ejecutar las fases de inferencia vistas en la secci√≥n anterior. 

    ```python
    for nombre_archivo in lista_archivos:
        if cat in nombre_archivo:
            etiqueta_esperada = "gato"
        elif dog in nombre_archivo:
            etiqueta_esperada = "perro"
        else:
            continue  # Saltar archivos que no sean de gatos o perros
            
        total_predicciones += 1
        
        ruta_imagen = os.path.join("<TEST_CARPETA_PATH>", nombre_archivo)
        
        # Aqu√≠ obtendriamos la predicci√≥n del modelo llamando a una funci√≥n que 
        # implemente las fases de inferencia
        etiqueta_predicha, probabilidad = predecir_imagen(ruta_imagen)

        if etiqueta_predicha == etiqueta_esperada:
            aciertos += 1
            media_probabilidad_aciertos += probabilidad
        else:
            info_error= {"archivo": nombre_archivo, "prediccion": etiqueta_predicha, 
                 "probabilidad": probabilidad}
            predicciones_incorrectas.append(info_error)
    




