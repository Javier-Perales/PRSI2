---
title: Sprint1. Geopolítica del Chip y la IA (Introducción)
description: En este sprint debemos entender el valor estratégico de la computación en el S.XXI. Analizaremos por qué las GPUs son el nuevo petróleo y cómo la arquitectura del hardware define la capacidad de una IA.
---

Iniciamos un nuevo proyecto de desarrollo enfocado en diseñar una infraestructura que soporte cargas de Inteligencia Artificial (IA). Simularemos un despliegue de hardware sobre una oficina técnica, tomando decisiones sobre CPU/GPU/NPU, redes corporativas y servicios en la nube.

Los objetivos de este proyecto son:

- Capacidad para seleccionar y dimensionar hardware específico para IA y servidores.
- Diseñar una topología de red escalable que garantice la segmentación del tráfico y la seguridad.
- Implementar servicios de red que permita el trabajo colaborativo (Web, BBDD, almacenamiento), asegurando la disponibilidad y el control de accesos.
- Generar documentación técnica profesional y gestionar estados de incertidumbre mediante trabajo colaborativo.

## Geopolítica del Chip

Antes de comprar hardware, debemos entender el valor estratégico de la computación en el S.XXI. Analizaremos por qué las GPUs son el nuevo "petróleo" y cómo la arquitectura del hardware define la capacidad de una IA.

---

La industria de los semiconductores se ha convertido en el eje de la economía y la defensa mundial, sustituyendo al petróleo como el recurso más crítico. Esta industria se caracteriza por una cadena de suministro altamente especializada y globalizada, donde ningún país es autosuficiente. El conflicto actual entre EE. UU. y China gira en torno al acceso a la tecnología de fabricación más avanzada (litografía EUV y chips de < 5nm), esencial tanto para la Inteligencia Artificial como para el armamento moderno.

!!! note "Guerra de Chips"

    Una vez visualizado el siguiente video [GUERRA DE CHIPS - El conflicto que puede cambiar el mundo](https://youtu.be/opNTOyD1Nx0?si=wnorNEsfX2-B_dpY), reflexiona sobre las siguientes cuestiones:

    1. ¿Qué tipos de estructuras empresariales se han formado en la industria de los semiconductores? En concreto, ¿qué papel juegan las empresas "foundries", "fabless"? ¿Existe algún tuipo de barrera de entrada a este mercado?
    2. ¿Por qué los semiconductores actúan como "cuellos de botella" en la economía global? ¿Qué factores contribuyen a su escasez y cómo afecta esto a otras industrias?
    3. ¿Qué entiendes por el conflicto del uso dual de los chips?
    4. ¿Qué es la soberanía tecnológica? ¿qué intentos están realizando EEUU y China para alcanzarla?


La industria de los semiconductores ha dejado de ser un mercado libre global para convertirse en un escenario de "Guerra Fría Tecnológica". Actualmente, el mundo se divide en dos grandes bloques que compiten por el control del futuro digital.

- **Bloque Occidental**: Liderado por EE. UU., con aliados en Europa, Japón y Corea del Sur. Este bloque controla la mayoría de las empresas de diseño de chips (NVIDIA, AMD, Intel) y las tecnologías de fabricación más avanzadas (TSMC, Samsung). EE. UU. ha impuesto restricciones a la exportación de tecnología avanzada a China para frenar su desarrollo tecnológico.

- **Bloque Oriental**: Liderado por China, que busca alcanzar la autosuficiencia tecnológica mediante inversiones masivas en I+D y la creación de su propia industria de semiconductores (SMIC, Huawei). China enfrenta desafíos debido a las restricciones impuestas por EE. UU., pero continúa avanzando en tecnologías clave como la IA y las redes 5G.

## El Ecosistema del Silicio

Como hemos visto en la sección anterior, en la industria de los semiconductores existen tres tipos principales de empresas que forman un ecosistema interdependiente:

- **Empresas *Fabless***: Se dedican al diseño y desarrollo de chips, pero no poseen fábricas propias. Ejemplos incluyen NVIDIA, AMD, Qualcomm y Apple. Estas empresas se centran en la innovación y el diseño de arquitecturas avanzadas.
- ***Foundries***: Son empresas especializadas en la fabricación de chips diseñados por las empresas fabless. Ejemplos destacados son TSMC (Taiwán), Samsung (Corea del Sur), y SMIC (China). 
- **Integrated Device Manufacturers (IDMs)**: Combinan el diseño y la fabricación de chips en una sola empresa. Ejemplos incluyen Intel y Samsung. Históricamente, los IDMs dominaban la industria, pero la tendencia actual favorece a las empresas fabless y foundries debido a la alta especialización requerida en cada etapa.

### CPUs vs GPUs

Durante décadas, los ordenadores han funcionado con un "cerebro central" que lo hacía todo, la **CPU**. Sin embargo, el auge de los móviles, y sobre todo, de la **inteligencia artificial**, ha cambiado las reglas del juego.

**Intel** lideró el mercado de las CPUs durante decadas, desde que IBM eligió sus procesadores para sus PCs en 1981. Sin embargo, un mercado emergente de videojuegos y gráficos 3D impulsó el desarrollo de las **GPUs** (unidades de procesamiento gráfico) por parte de empresas como **Nvidia** y **AMD**.

Las **GPUs** fueron diseñadas inicialmente para acelerar el procesamiento gráfico de los videojuegos, ya que el renderizado de imágenes requieren realizar millones de operaciones matemáticas simples en paralelo. A diferencia de las CPUs, que están optimizadas para tareas de propósito general.

Esta característica de las GPUs las hicieron ideales posteriormente para la minería de criptomonedas y, más recientemente, para la inteligencia artificial, donde el entrenamiento de modelos requiere realizar cálculos masivos en paralelo.

Veamos en el siguiente video una explicación sencilla de las diferencias entre CPU y GPU: [CPU vs GPU - What's the Difference?](https://www.youtube.com/watch?v=U8vE2P01H5o)

!!! note "Diferencias entre CPU y GPU"

    - ¿Qué analogía utiliza el video para explicar la diferencia entre CPU y GPU?
    - Cantidad vs Complejidad: ¿Cómo es la diferencia en los núcleos "cores" entre CPU y GPU?
    - Flexibilidad:¿Por qué no usamos una GPU para ejecutar Windows o navegar por Internet?
    - El flujo de datos: ¿Cómo se diferencia la memoria de la gráfica (VRAM) de la memoria RAM del sistema?

#### Arquitecturas de CPU: x86 vs ARM

Normalmente cuando hablamos de lo bueno o malo que es un procesador, nos referimos a la velocidad de reloj (*Ghz*) y como mucho, al número de núcleos que tiene. Sin embargo, la mayoría de usuarios no son conscientes de un aspecto fundamental que define el rendimiento y la eficiencia de un procesador: su **arquitectura**.

Cuando decimos que un procesador ejecuta instrucciones, no nos referimos a instrucciones definidas en un lenguaje como *Python* o *Java*; los procesadores solo entienden unas instrucciones muy básicas denominadas genericamente como *lenguaje máquina*. El conjunto de reglas que define ese lenguaje se llama **ISA (Instruction Set Architecture)**

Hoy en día, el mundo de las CPUs se divide en dos grandes *idiomas*: el **x86** y el **ARM**.

##### **x86: La "Fuerza Bruta" (CISC)**

Creado por Intel en 1978 (Intel 8086), tiene la filosofía de "**hacer lo máximo en el menor número de instrucciones**". Esto se traduce en un conjunto de instrucciones muy amplio y complejo (**CISC, Complex Instruction Set Computing**), donde cada instrucción puede realizar múltiples operaciones básicas.

La ventaja de la arquitectura x86 es su **potencia bruta inigualable** para tareas pesadas. Sin embargo, su **complejidad y consumo energético lo hacen menos adecuado para dispositivos móviles y aplicaciones que requieren eficiencia energética**.

En la actualidad, **Intel** y **AMD** dominan el mercado de CPUs x86, siendo la elección preferida para ordenadores de escritorio, portátiles y servidores de alto rendimiento.

##### **ARM: La "Eficiencia" (RISC)**

El origen de ARM se remonta a 1983, cuando Acorn Computers desarrolló un procesador basado en la filosofía **RISC (Reduced Instruction Set Computing)**, que busca simplificar el conjunto de instrucciones para mejorar la eficiencia y reducir el consumo energético.

Su filosofía se basa en "**hacer menos, pero hacerlo más rápido**". Las instrucciones ARM son más simples y rápidas de ejecutar, lo que permite un diseño de procesadores más eficiente y con menor consumo energético.

Por tanto, su ventaja principal es su **eficiencia energética y rendimiento por vatio**, lo que lo hace ideal para dispositivos móviles y aplicaciones embebidas.

---
El modelo de negocio de ARM es diferente al de Intel o AMD. ARM Holdings diseña arquitecturas y licencia a otras empresas (como Qualcomm, Apple, Samsung) para fabricar sus propios chips basados en ARM. Esto ha llevado a una **gran diversidad de implementaciones** y una **amplia adopción en dispositivos móviles**.

Podemos comparar a ARM Holdings con un estudio de arquitectura de élite. Su especialidad es crear los planos maestros de edificios altamente eficientes y sostenibles. Sin embargo, ellos no ponen los ladrillos; venden esos planos a otras empresas (las constructoras), que son quienes finalmente levantan el edificio, adaptando el diseño original con reformas y añadidos según lo que necesite su cliente final.

En la siguiente tabla relacionamos las diferentes versiones de arquitecturas ARM con sus productos estrella.


| Era / Versión ARM | Año aprox. | La Innovación Técnica | El Producto Estrella |
| :--- | :--- | :--- | :--- |
| **1. La Era "Pocket"**<br>*(ARMv4 / v5)* | 1995 - 2005 | **Bajo consumo extremo.** No había potencia para Sistemas Operativos complejos, solo firmwares básicos. | **Nokia 3310** (Jugar a la serpiente) y **Game Boy Advance / Nintendo DS**. La batería duraba semanas. |
| **2. La Revolución Smartphone**<br>*(ARMv7 - 32 bit)* | 2008 - 2012 | **Multinúcleo.** Los móviles empiezan a ser "mini ordenadores" con internet real. | **iPhone 4**, **Samsung Galaxy S2**, **Raspberry Pi 1**. Aquí nacen Android e iOS tal como los conocemos. |
| **3. El Salto a 64 Bits**<br>*(ARMv8 - AArch64)* | 2013 - 2020 | **El Gran Cambio.** Apple sorprende con el chip A7. Permite más de 4GB de RAM y cálculos complejos de escritorio. | **iPhone 5S** (El pionero), **Nintendo Switch** (Chip Nvidia Tegra), **PlayStation Classic**. |
| **4. La Era de la IA**<br>*(ARMv9)* | 2021 - Hoy | **Inteligencia Artificial.** Seguridad (Confidential Computing) y Vectores (SVE2). El chip está diseñado para "pensar", no solo calcular. | **Samsung S24** (Snapdragon 8 Gen 3), **Apple M3/M4**, Superordenadores (**Nvidia Grace**). |

El futuro de los procesadores ARM es prometedor desde que Apple anunciara en 2020 su transición de Intel a ARM para sus ordenadores Mac. Los chips Apple Silicon (M1, M2, M3) han demostrado que ARM puede competir e incluso superar a las CPUs x86 en rendimiento y eficiencia energética en el ámbito de los ordenadores personales.

Recursos:

- [ARM vs x86 - Explicación técnica](https://www.youtube.com/watch?v=4izGC6YbMtU)
- [¿ARM es el futuro?](https://www.youtube.com/watch?v=S50t7J7_3lE)

<!--

Intel dominó el mercado de CPUs durante años con la arquitectura x86, pero la llegada de los smartphones impulsó el desarrollo de arquitecturas alternativas como ARM, que ofrecen mayor eficiencia energétiva y rendimiento por vatio. Empresas como Apple y Qualcomm han adoptado ARM para sus procesadores móviles, desplazando a Intel en este segmento. 

Igualmente llego tarde a la IA, donde las **GPUs** (unidades de procesamiento gráfico) demostraron ser mucho más eficientes para las tareas de aprendizaje automático debido a su capacidad para manejar operaciones paralelas masivas. Nvidia y AMD se convirtieron en los líderes indiscutibles en este campo, con Nvidia dominando el mercado de GPUs para IA gracias a su arquitectura CUDA y su ecosistema de software.



### Bloque Occidental

El Bloque Occidental, liderado por EEUU, domina el diseño y la fabricación de chips avanzados, tienen como estrategia fabricar y controlar el acceso a la tecnología de punta para mantener su supremacía tecnológica (*friend-shoring*)

#### Nvidia

Nvidia es la empresa lider en el diseño de microprocesadores de alto rendimiento, especialmente en el ámbito de las GPUs para IA.

Aunque durante años fue conocida principalmente por sus tarjetas gráficas para videojuegos, la compañia supo anticiparse y adaptar esa tecnología al cálculo masivo que requieren los modelos de IA. Sus GPUs se han convertido en el estándar de facto para entrenar y desplegar modelos como ChatGPT. A esta tecnología se le suma un ecosistema de software propio (*CUDA*) que facilita a los desarrolladores aprovechar al máximo el potencial de sus chips.

Este liderazgo ha hecho que los mercados financieros valoren a Nvidia como una de las empresas más estratégicas del mundo, con una capitalización bursátil que supera los [4,25 trillones de dólares en 2025](https://es.investing.com/equities/nvidia-corp) (Trillones USA, es decir, billones en Europa). Para ver la magnitud de esta cifra, vamos a compararlo con el PIB de algunos países:

- PIB de Francia (2024) : 3,2 trillones de dólares
- PIB de Reino Unido (2024) : 3,1 trillones de dólares
- PIB de India (2024) : 3,7 trillones de dólares
- PIB de España (2024) : 1,6 trillones de dólares

EEUU ha impuesto restricciones específicas de exportación a algunos chips Nvidia a China por su potencial uso dual. Esto está llevando al juego del gato y ratón, donde EEUU prohibe chips que superen cierta velocidad y potencia de cálculo, y Nvidia diseña nuevos chips que se ajustan a esas limitaciones pero que siguen siendo muy potentes para no perder el mercado chino. El gobierno de EEUU vuelve a ajustar nuevas restricciones, y así sucesivamente. 



| Etapa | Fecha | Chip "Rey" (Global) | Estatus en China | Contexto Geopolítico y Técnico |
| :--- | :--- | :--- | :--- | :--- |
| **1. Libre Comercio** | Pre-Oct 2022 | **Nvidia A100** (Ampere) | ✅ **Permitido** | Era de colaboración. Los laboratorios chinos compran miles de chips A100 para entrenar sus primeros modelos de IA. |
| **2. El Primer Bloqueo** | Oct 2022 | **Nvidia H100** (Hopper) | ❌ **PROHIBIDO** (H100 y A100) | EE. UU. impone límites a la *velocidad de interconexión* (ancho de banda) para evitar que China construya clústeres militares. |
| **3. La Solución "Lite"** | Nov 2022 - Oct 2023 | **Nvidia H100** | ⚠️ **Alternativa: H800 / A800** | Nvidia modifica el chip recortando la velocidad de conexión para cumplir la ley. El H800 es legal y muy vendido en China. |
| **4. Cierre del "Agujero"** | Oct 2023 | **Nvidia H100** | ❌ **PROHIBIDO** (H800 y RTX 4090) | EE. UU. endurece la norma ("Densidad de Rendimiento"). Se prohíben las versiones "Lite" e incluso gráficas de consumo como la RTX 4090. |
| **5. La Era Actual** | 2024 - Presente | **Nvidia B200** (Blackwell) | ⚠️ **Alternativa: H20** | La brecha se agranda. El H20 es un chip muy limitado en potencia bruta. China empieza a depender de Huawei (Ascend) por necesidad. |

Recurso adicional:

- [The Nvidia Office Tour](https://www.youtube.com/watch?v=qDg_3eqssig)

-->

